{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4366916b-3e8b-45d0-b064-81946aee9b6a",
   "metadata": {},
   "source": [
    "# HuggingFace TrieGuided Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4914c3a352ee5ce8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4419fb97-221c-4238-859e-119effe9fbdc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:23.623301Z",
     "start_time": "2023-11-27T10:21:23.577957Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "torch_device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fuad/opt/miniconda3/envs/lexflow/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:23.723035Z",
     "start_time": "2023-11-27T10:21:23.585060Z"
    }
   },
   "id": "83b7ae86dd907579"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "103c1a64-3d79-49a8-a445-0df9170df7f0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:44.441221Z",
     "start_time": "2023-11-27T10:21:23.725332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trieregex in /Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/site-packages (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install outlines -q\n",
    "!pip install -q transformers\n",
    "!pip install -q openai\n",
    "!pip install -q datasets\n",
    "!pip install -q accelerate\n",
    "!pip install trieregex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import site\n",
    "import os\n",
    "import transformers  # replace 'my_library' with the actual library name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:48.024103Z",
     "start_time": "2023-11-27T10:21:44.444478Z"
    }
   },
   "id": "cfdc9fd56b6355"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/site-packages/transformers\n"
     ]
    }
   ],
   "source": [
    "library_path = os.path.dirname(transformers.__file__)\n",
    "print(library_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:48.043859Z",
     "start_time": "2023-11-27T10:21:48.028433Z"
    }
   },
   "id": "19b7c7a4e8b6bce6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea0b6c4-d6d9-4e9a-9b91-bf8899ffbe64",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:48.044435Z",
     "start_time": "2023-11-27T10:21:48.036835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/fuad/Documents/projects/lexflow/src/notebooks', '/Users/fuad/Documents/projects/lexflow', '/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/site-packages/transformers', '/Users/fuad/opt/miniconda3/envs/lexflow/lib/python310.zip', '/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10', '/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/lib-dynload', '', '/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc3ffc-e2a3-4539-b4b4-e0199273ba65",
   "metadata": {},
   "source": [
    "## Â Exploring api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28327965-1c4e-4eb7-8036-5734595fbb9d",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:53.033668Z",
     "start_time": "2023-11-27T10:21:48.045870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fuad/opt/miniconda3/envs/lexflow/lib/python3.10/site-packages/beartype/_util/module/utilmodimport.py:149: BeartypeModuleUnimportableWarning: Ignoring module \"onnx\" importation exception:\n",
      "\tImportError: attempted relative import beyond top-level package\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Open-Orca/Mistral-7B-OpenOrca\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6fe4f82-6c64-46a5-970f-12cbfc61eecd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:53.051255Z",
     "start_time": "2023-11-27T10:21:53.036868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "GenerationConfig {\n  \"bos_token_id\": 50256,\n  \"eos_token_id\": 50256\n}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcefbb5-be94-45e5-9624-d015af7df5be",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:53.090963Z",
     "start_time": "2023-11-27T10:21:53.047520Z"
    }
   },
   "outputs": [],
   "source": [
    "from custom_utils import CustomLogitsProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3a251fe-696d-458d-b037-ef887fa03c5b",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-27T10:21:53.114727Z",
     "start_time": "2023-11-27T10:21:53.059085Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers.generation.logits_process import LogitsProcessorList\n",
    "\n",
    "logit_processors = LogitsProcessorList([CustomLogitsProcessor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "input_ids = tokenizer('I enjoy walking with my cute dog', return_tensors='pt')  #.to(torch_device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0e6c4d5-86bb-4d42-9f0c-0a037f821498"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(**input_ids, \n",
    "               max_new_tokens=40,\n",
    "               do_sample=True,\n",
    "               top_k=50,\n",
    "               # num_beams=5,\n",
    "               early_stopping=True,\n",
    "               # logits_processor=logit_processors\n",
    "               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:26:45.816983Z",
     "start_time": "2023-11-27T10:26:43.615102Z"
    }
   },
   "id": "ddc22afa-508e-4377-b224-3ec5fef94996"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 47])\n",
      "I enjoy walking with my cute dog and I like seeing it in a variety of different situations and I think it would have been much better if I could stay outside a lot of time. My dog has never had a break but I like\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:27:10.845432Z",
     "start_time": "2023-11-27T10:27:10.831036Z"
    }
   },
   "id": "fa97716e232d0d0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building document index "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33000cd26fb2675c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### trie\n",
    "this one seems to work as i want but its memory intensive. can optimise later"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6d5dcf773f9537b"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from custom_utils import read_document\n",
    "document = read_document('document.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:30:13.943080Z",
     "start_time": "2023-11-27T10:30:13.926584Z"
    }
   },
   "id": "522a56c7f2807298"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "5025"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:30:19.943320Z",
     "start_time": "2023-11-27T10:30:19.917136Z"
    }
   },
   "id": "4810c5891c502c22"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "documents = [document]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:10:17.650394Z",
     "start_time": "2023-11-23T16:10:17.392496Z"
    }
   },
   "id": "d1211808eacf74ce"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from custom_utils import DocumentIndex"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:14:33.871491Z",
     "start_time": "2023-11-23T16:14:33.309921Z"
    }
   },
   "id": "8c529352247a1024"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "([',', 'Ä -', 'Ä was', 'Ä said'], 'Mrs Braverman,')"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index = DocumentIndex(documents, tokenizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:20:23.994698Z",
     "start_time": "2023-11-23T16:20:19.629943Z"
    }
   },
   "id": "577082039af4cd98"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "{'next_words': {' cabinet': 1},\n 'next_ids': {13447: 1},\n 'full_text_list': [\" Mr Sunak's cabinet\"]}"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index.get_next_words(\" Mr Sunak's\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T16:39:06.839996Z",
     "start_time": "2023-11-23T16:39:06.782827Z"
    }
   },
   "id": "85cac21e1f1426f2"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "{'next_words': {' had': 1},\n 'next_ids': {550: 1},\n 'full_text_list': ['Mr Sunak had']}"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index.get_next_words(\"Mr Sunak\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:05:12.934677Z",
     "start_time": "2023-11-23T17:05:12.878314Z"
    }
   },
   "id": "d37ff968ffd7d48e"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "{'next_words': {'\\n': 1},\n 'next_ids': {198: 1},\n 'full_text_list': [' Mrs Braverman.\\n']}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index.get_next_words(\" Mrs Braverman.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:05:16.648708Z",
     "start_time": "2023-11-23T17:05:16.591390Z"
    }
   },
   "id": "bc1ef70f1c048adc"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "{'next_words': {}, 'next_ids': {}, 'full_text_list': []}"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index.get_next_words(\"Mrs Braverman.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:06:16.472668Z",
     "start_time": "2023-11-23T17:06:16.422947Z"
    }
   },
   "id": "ff2deda61ca35b8e"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "{'next_words': {',': 1, ' -': 1, ' was': 1, ' said': 2},\n 'next_ids': {11: 1, 532: 1, 373: 1, 531: 2},\n 'full_text_list': ['Mrs Braverman,',\n  'Mrs Braverman -',\n  'Mrs Braverman was',\n  'Mrs Braverman said']}"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_index.get_next_words(\"Mrs Braverman\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-23T17:05:26.201881Z",
     "start_time": "2023-11-23T17:05:26.152924Z"
    }
   },
   "id": "85d29a2f3a96e792"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing on Document"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f56c66920b624e"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "512"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document[:512])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:39:25.651105Z",
     "start_time": "2023-11-27T10:39:25.632289Z"
    }
   },
   "id": "267ce950666e232c"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "'Suella Braverman accuses Rishi Sunak of betrayal in scathing resignation letter\\nPublished\\n26 minutes ago\\n\\nShare\\nSuella Braverman and Rishi Sunak\\nIMAGE SOURCE,PA MEDIA\\nBy Becky Morton & Paul Seddon\\nBBC News\\nSuella Braverman has launched a full-scale attack on her old boss Rishi Sunak, a day after he sacked her as home secretary.\\n\\nIn a blistering letter to the prime minister, she said he had repeatedly failed on key policies and broken pledges over immigration.\\n\\nMr Sunak had adopted \"wishful thinking\" to \"avoid having to make hard choices\", she wrote.\\n\\nAnd she accused him of having \"no real intention\" of keeping his promises.\\n\\nADVERTISEMENT\\n\\nMrs Braverman, a leading figure on the right of the party, claimed she struck a secret deal to serve in Mr Sunak\\'s cabinet in exchange for a series of commitments, after Liz Truss\\'s premiership imploded last year.\\n\\nHer support, she added, had been a \"pivotal factor\" in allowing Mr Sunak to win the support of Tory MPs and enter No 10.\\n\\nA No 10 spokesman thanked Mrs Braverman for her service, but added: \"The prime minister was proud to appoint a strong, united team yesterday focused on delivering for the British people.\"\\n\\nSuella Braverman\\'s letter to Rishi Sunak in full\\nChris Mason: A \\'direct, unflinching assault\\'\\nWho is Suella Braverman?\\nThe former home secretary\\'s explosive letter comes on the eve of a key Supreme Court ruling on the legality of the government\\'s postponed scheme to send some asylum seekers to Rwanda to claim asylum there.\\n\\nMrs Braverman - who once described the policy as \"my dream, my obsession\" - said she had argued within government for curbs on human rights law to ensure the policy was not derailed by legal challenges.\\n\\nBut compromises from Mr Sunak during the passage of the Illegal Migration Act, she wrote, had left the government \"vulnerable to being thwarted yet again\" by European judges, even if it wins the Supreme Court ruling.\\n\\nIf the ruling goes against the government, she added, he would have \"wasted a year\" on the flagship law to stop small boat crossings, \"only to arrive back at square one\".\\n\\n\"Worse than this, your magical thinking - believing that you can will your way through this without upsetting polite opinion - has meant you have failed to prepare any sort of credible \\'Plan B\\',\" she wrote.\\n\\nA No 10 spokesman said the government had \"brought forward the toughest legislation to tackle illegal migration this country has seen and has subsequently reduced the number of boat crossings by a third this year\".\\n\\n\"And whatever the outcome of the Supreme Court tomorrow, he will continue that work,\" the spokesman added.\\n\\n\\'Plan not working\\'\\nIn her letter, the former home secretary told Mr Sunak he had \"manifestly and repeatedly\" failed to deliver on policy priorities.\\n\\n\"Either your distinctive style of government means you are incapable of doing so,\" she wrote.\\n\\n\"Or, as I must surely conclude now, you never had any intention of keeping your promises.\"\\n\\nShe added: \"Someone needs to be honest: your plan is not working, we have endured record election defeats, your resets have failed and we are running out of time. You need to change course urgently.\"\\n\\nMrs Braverman was sacked from her role on Monday, after opponents accused her of stoking tensions ahead of pro-Palestinian marches in London.\\n\\nShe lost her job days after she claimed police had applied a \"double standard\" to protesters, in an article for the Times newspaper.\\n\\nMrs Braverman said Mr Sunak had failed \"to rise to the challenge posed by the increasingly vicious antisemitism and extremism displayed on our streets\".\\n\\n\"I have become hoarse urging you to consider legislation to ban the hate marches and help stem the rising tide of racism, intimidation and terrorist glorification threatening community cohesion,\" she added, accusing the PM of putting off \"tough decisions in order to minimise political risk to yourself\".\\n\\n\\'Tory psychodrama\\'\\nIn her letter, Mrs Braverman said the conditions under which she agreed to become home secretary in October 2022 were set out in a \"document with clear terms\".\\n\\nSources close to Mrs Braverman claim Mr Sunak read and agreed the document the letter refers to, which had been drawn up by Mrs Braverman.\\n\\nThey say he took a copy and there were witnesses.\\n\\nMrs Braverman said the agreement included \"firm assurances\" on cutting legal migration, inserting measures to override the European Convention on Human Rights (ECHR) into legislation to stop small boat crossings, delivering key Brexit legislation and issuing \"unequivocal\" guidance to schools on protecting biological sex and safeguarding single-sex spaces.\\n\\nShe accused Mr Sunak of \"a betrayal of our agreement\" and \"a betrayal of your promise to the nation that you would do \\'whatever it takes\\' to stop the boats\".\\n\\nLabour shadow minister Lisa Nandy said the letter was \"just the latest instalment in a Tory psychodrama that\\'s been playing out over the last 13 years, holding the rest of the country to ransom while the Tories fight among themselves\".'"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:47:43.527104Z",
     "start_time": "2023-11-27T10:47:43.493003Z"
    }
   },
   "id": "3f773c4e3c9e8596"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'trunctation': True} not recognized.\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(document, max_length=9, trunctation=True,return_tensors='pt')  #.to(torch_device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:45:18.514964Z",
     "start_time": "2023-11-27T10:45:18.497914Z"
    }
   },
   "id": "dbc8467176cff452"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 9])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids['input_ids'].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:45:24.915176Z",
     "start_time": "2023-11-27T10:45:24.892976Z"
    }
   },
   "id": "50a17f6b24ee79fb"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   50,   518,  8466,  9718,   332,   805, 35062,   371, 21644])\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Suella Braverman accuses Rishi'"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_ids['input_ids'].squeeze())\n",
    "tokenizer.decode(input_ids['input_ids'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:47:14.436696Z",
     "start_time": "2023-11-27T10:47:14.420513Z"
    }
   },
   "id": "85f8270d330bfc6b"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(**input_ids, \n",
    "               max_new_tokens=40,\n",
    "               do_sample=True,\n",
    "               top_k=50,\n",
    "               # num_beams=5,\n",
    "               early_stopping=True,\n",
    "               # logits_processor=logit_processors\n",
    "               )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:45:33.605077Z",
     "start_time": "2023-11-27T10:45:31.165414Z"
    }
   },
   "id": "b000e38a31c8aab7"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 49])\n",
      "Suella Braverman accuses Rishi of \"rejecting\" the campaign \"by spreading fear and bigotry.\"\n",
      "\n",
      "\"I was struck by the way in which Rishi continues to make a show of supporting extremist views, rather than\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:45:45.726436Z",
     "start_time": "2023-11-27T10:45:45.708343Z"
    }
   },
   "id": "d3e3157bb34fe035"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1d9dd0c00084fbd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Old"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab59393b7be563c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### document graph  - old\n",
    "\n",
    "this works word by word. it only takes the last word as history "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31a9559e3c11689b"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'said', 'and', 'for', 'has', 'accuses', '-', 'claim', 'was'}\n"
     ]
    }
   ],
   "source": [
    "from custom_utils import build_word_graph\n",
    "# Example usage\n",
    "# document = \"hello my name is hello his name is ....\"\n",
    "word_graph = build_word_graph(document)\n",
    "\n",
    "# Now you can query the graph for what comes after \"hello\"\n",
    "print(word_graph[\"Braverman\"])  # Outputs: {'my', 'his'}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-27T10:34:01.082433Z",
     "start_time": "2023-11-27T10:34:01.060312Z"
    }
   },
   "id": "2deec38c8bb2cb04"
  },
  {
   "cell_type": "markdown",
   "id": "3a699611-f2c2-4bc3-9860-5c5cbba7726e",
   "metadata": {},
   "source": [
    "## testing huggingface - old. now using logits processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0742eeff-e9c5-4adf-8e0d-774b20e993c2",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:48.504784Z",
     "start_time": "2023-11-23T14:48:43.409439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input word: 'The'\n",
      "Predicted next word: '\n",
      "'\n",
      "Actual next word: ' current'\n",
      "\n",
      "Input word: ' current'\n",
      "Predicted next word: ' state'\n",
      "Actual next word: ' weather'\n",
      "\n",
      "Input word: ' weather'\n",
      "Predicted next word: ' is'\n",
      "Actual next word: ' is'\n",
      "\n",
      "Input word: ' is'\n",
      "Predicted next word: ' not'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Encode the input text\n",
    "input_text = \"The current weather is\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Get the model's output (logits)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "probabilities = softmax(predictions)\n",
    "\n",
    "# Iterate through each word in the input and check the prediction for the next word\n",
    "for i in range(len(input_ids[0]) - 1):\n",
    "    # Get the index of the actual next word\n",
    "    actual_next_word_id = input_ids[0][i + 1].item()\n",
    "    # Get the probability distribution for the next word\n",
    "    next_word_probabilities = probabilities[0, i]\n",
    "    # Get the predicted token ID with the highest probability for the next word\n",
    "    predicted_next_word_id = next_word_probabilities.argmax().item()\n",
    "\n",
    "    # Decode the predicted and actual next words\n",
    "    predicted_token = tokenizer.decode([predicted_next_word_id])\n",
    "    actual_next_word = tokenizer.decode([actual_next_word_id])\n",
    "\n",
    "    print(f\"Input word: '{tokenizer.decode([input_ids[0][i].item()])}'\")\n",
    "    print(f\"Predicted next word: '{predicted_token}'\")\n",
    "    print(f\"Actual next word: '{actual_next_word}'\")\n",
    "    print()\n",
    "\n",
    "# Now handle the last token separately since there's no actual next word in the input\n",
    "last_word_probabilities = probabilities[0, -1]\n",
    "predicted_next_word_id_for_last = last_word_probabilities.argmax().item()\n",
    "predicted_token_for_last = tokenizer.decode([predicted_next_word_id_for_last])\n",
    "\n",
    "print(f\"Input word: '{tokenizer.decode([input_ids[0][-1].item()])}'\")\n",
    "print(f\"Predicted next word: '{predicted_token_for_last}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "145fc1a3-e69c-4f42-a0fd-e347f4054227",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:48.556991Z",
     "start_time": "2023-11-23T14:48:48.497016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 50257])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1eedb1b2-ed06-48c2-a3ed-cf22d21ba340",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:48.625363Z",
     "start_time": "2023-11-23T14:48:48.549982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sunny\n"
     ]
    }
   ],
   "source": [
    "# Get the logits for the last token in the input\n",
    "last_token_logits = predictions[:, -1, :]\n",
    "\n",
    "# Define candidate words\n",
    "candidate_words = [\"sunny\", \"rainy\", \"cloudy\", \"windy\"]\n",
    "\n",
    "# Retrieve the indices of the candidate words\n",
    "candidate_indices = [tokenizer.encode(word)[0] for word in candidate_words]\n",
    "\n",
    "# Extract the logits for the candidate words\n",
    "candidate_logits = last_token_logits[:, candidate_indices]\n",
    "\n",
    "# Find the most likely candidate word\n",
    "most_likely_word_index = candidate_logits.argmax(-1).item()\n",
    "predicted_word = candidate_words[most_likely_word_index]\n",
    "\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "93be0b6d-5999-458c-aa9f-928c501123d0",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:48.684885Z",
     "start_time": "2023-11-23T14:48:48.610579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6fc88dbd-c4d8-49d6-8f38-85abea1562cb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:48.741401Z",
     "start_time": "2023-11-23T14:48:48.655986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4])"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ce90121-37cf-47b4-ac9a-955c206f88c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:51.527069Z",
     "start_time": "2023-11-23T14:48:48.708029Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f516dd94-6df0-4d1d-87db-2843d8b56ba3",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:51.829723Z",
     "start_time": "2023-11-23T14:48:51.526321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encode the input text\n",
    "input_text = \"Extract from the text what Mrs Braverman said\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Get the model's output (logits)\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# Apply softmax to convert logits to probabilities\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "probabilities = softmax(predictions)\n",
    "\n",
    "# Now handle the last token separately since there's no actual next word in the input\n",
    "last_word_probabilities = probabilities[0, -1]\n",
    "last_token_logits = predictions[:, -1, :]\n",
    "\n",
    "# Define the trie with potential next words\n",
    "# trie = # (Assume this is your trie object which has the method search_next_words(sequence))\n",
    "\n",
    "# Get the possible next words from the trie given the sequence of tokens\n",
    "sequence_of_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "next_words_from_trie = trie.search_next_words(sequence_of_tokens)\n",
    "print(next_words_from_trie)\n",
    "# Convert these possible next words to their corresponding token IDs\n",
    "next_word_ids_from_trie = {tokenizer.encode(word)[0] for word in next_words_from_trie}\n",
    "\n",
    "# Mask the probabilities\n",
    "masked_probabilities = last_word_probabilities.clone()  # Clone the tensor to avoid modifying the original probabilities\n",
    "for idx in range(masked_probabilities.size(0)):\n",
    "    if idx not in next_word_ids_from_trie:\n",
    "        masked_probabilities[idx] = 0\n",
    "\n",
    "# Renormalize the probabilities\n",
    "masked_probabilities /= masked_probabilities.sum()\n",
    "\n",
    "# Find the most likely word from the trie\n",
    "most_likely_word_id = masked_probabilities.argmax().item()\n",
    "predicted_word = tokenizer.decode([most_likely_word_id])\n",
    "\n",
    "print(predicted_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2cdf20c2-ac40-40a6-9ef4-fa202ed23688",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:52.124258Z",
     "start_time": "2023-11-23T14:48:51.822697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the function to predict the next word using a trie for restrictions\n",
    "def predict_next_word(input_text, trie=None, use_trie=True):\n",
    "    \"\"\"\n",
    "    Predicts the next word using GPT-2 model with an option to restrict predictions based on a trie.\n",
    "    \n",
    "    Parameters:\n",
    "    input_text (str): The input text string for which we want to predict the next word.\n",
    "    trie (Trie object): An optional trie object for restricting predictions.\n",
    "    use_trie (bool): A flag to determine whether to use the trie for restricting predictions.\n",
    "    \n",
    "    Returns:\n",
    "    str: The predicted next word.\n",
    "    \"\"\"\n",
    "    # Encode the input text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "    # Get the model's output (logits)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        predictions = outputs[0]\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "    probabilities = softmax(predictions)\n",
    "\n",
    "    # Get the logits and probabilities for the last token in the input\n",
    "    last_token_logits = predictions[:, -1, :]\n",
    "    last_word_probabilities = probabilities[0, -1]\n",
    "\n",
    "    # If the trie is provided and we're using it to restrict predictions\n",
    "    if trie and use_trie:\n",
    "        # Get the sequence of tokens from the input text\n",
    "        sequence_of_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "        # Get the possible next words from the trie given the sequence of tokens\n",
    "        next_words_from_trie = trie.search_next_words(sequence_of_tokens)\n",
    "\n",
    "        # Convert these possible next words to their corresponding token IDs\n",
    "        next_word_ids_from_trie = {tokenizer.encode(word, add_prefix_space=True)[0] for word in next_words_from_trie}\n",
    "\n",
    "        # Mask the probabilities for tokens not in the trie's next words\n",
    "        mask = torch.full_like(last_word_probabilities, fill_value=float('-inf'))\n",
    "        for idx in next_word_ids_from_trie:\n",
    "            mask[idx] = 0\n",
    "        masked_logits = last_token_logits + mask\n",
    "\n",
    "        # Apply softmax to convert masked logits to probabilities\n",
    "        masked_probabilities = softmax(masked_logits)\n",
    "    else:\n",
    "        masked_probabilities = last_word_probabilities\n",
    "\n",
    "    # Get the token ID with the highest probability\n",
    "    most_likely_word_id = masked_probabilities.argmax().item()\n",
    "    # Decode the token ID to get the word\n",
    "    predicted_word = tokenizer.decode([most_likely_word_id])\n",
    "\n",
    "    return predicted_word\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "predicted_word = predict_next_word(document[:512] + \"Extract from the text what Mrs Braverman said:'\", trie,\n",
    "                                   use_trie=True)\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecd29d2e-a0ca-46e9-b5c2-e66fa676a4a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T14:48:52.173411Z",
     "start_time": "2023-11-23T14:48:52.115841Z"
    }
   },
   "outputs": [],
   "source": [
    "# gotta do some proper decoding\n",
    "# why am i getting ! it should always be one of the words\n",
    "# maybe there is a need for fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3a08db98d54636ed"
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "name": "conda-env-lexflow-py",
   "language": "python",
   "display_name": "Python [conda env:lexflow] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "c8dfa52194188e48d6802840b718748a7140cbefa937517cab1c2b201bcac497"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
