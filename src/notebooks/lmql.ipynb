{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33c080f-afad-446b-9908-b7db78c1249d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee41105-082f-4c6b-83f2-0e56af7aefd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6e62ff-99fc-4a97-9a9e-2f5760a45652",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# print(os.environ.get('OPENAI_API_KEY'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837fcf21-7fef-4baa-b3ae-4edad1324fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"\\n\\n\\n\\nI'm not sure what you\"]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmql\n",
    "import asyncio\n",
    "\n",
    "@lmql.query\n",
    "async def hello():\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"yay[WHO]\"\n",
    "        return WHO\n",
    "    from\n",
    "        \"openai/text-ada-001\"\n",
    "    where\n",
    "        len(TOKENS(WHO)) < 10\n",
    "    '''\n",
    "\n",
    "# run 10 instances of 'hello' in parallel\n",
    "await asyncio.gather(hello())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edb2d7b-c074-4c60-854b-f996068a2017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = lmql.query('argmax \"yay[WHO]\" from \"openai/text-ada-001\" where len(TOKENS(WHO)) < 10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4102ab5b-c5fb-4e6c-937c-f17f9599f21f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LMQLResult(prompt=\"yay\\n\\n\\n\\nI'm not sure what you\", variables={'WHO': \"\\n\\n\\n\\nI'm not sure what you\"}, distribution_variable=None, distribution_values=None)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await q()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2977282-cea0-4286-b8ba-5265230889d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LMQLResult(prompt='Hello\\n\\nHello, welcome to our website.', variables={'WHO': '\\n\\nHello, welcome to our website.'}, distribution_variable=None, distribution_values=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await lmql.run('argmax \"Hello[WHO]\" from \"openai/text-ada-001\" where len(TOKENS(WHO)) < 10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b5feeb-c58b-488e-8c47-18e237bd1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def classify_review(review):\n",
    "  '''argmax\n",
    "    \"\"\"Review: {review}\\n\n",
    "    Q: What is the underlying sentiment of this review and why?\\n\n",
    "    A:[ANALYSIS]\\n\n",
    "    Based on this, the overall sentiment of the message can be considered to be [CLASSIFICATION]\"\"\"\n",
    "  from\n",
    "    \"openai/text-davinci-003\"\n",
    "  WHERE\n",
    "    CLASSIFICATION in [\"positive\", \"neutral\", \"negative\"]\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fe87d22-0be2-451f-a7b6-29e2ed710878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def classify_review(review):\n",
    "  '''argmax\n",
    "    \"\"\"Review: {review}\\n\n",
    "    Q: What is the underlying sentiment of this review and why?\\n\n",
    "    A:[ANALYSIS]\\n\"\"\"\n",
    "  from\n",
    "    \"openai/gpt-3.5-turbo\"\n",
    "\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e0b7b-0f81-4a2a-b490-2ae96a9c1154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9c85e4a2-4cbf-4727-8abb-993f63eec60a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer = lmql.query(classify_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90677f91-c5ea-4aaa-af26-5510f8eef56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27a1f15c-52a6-44db-a012-edc3fac8cce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LMQLResult(prompt='Review: this is bad\\n\\nQ: What is the underlying sentiment of this review and why?\\n\\nA:  The underlying sentiment of this review is negative because the reviewer states that \"this is bad.\"\\n', variables={'ANALYSIS': '  The underlying sentiment of this review is negative because the reviewer states that \"this is bad.\"'}, distribution_variable=None, distribution_values=None)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await answer('this is bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271d387-e949-4d11-9952-963448fcaab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "not \"\\n\" in ANALYSIS\n",
    "ANALYSIS in [\" positive\", \" neutral\", \" negative\"]\n",
    "not \"Q:\" in THING\n",
    "and not \"Q.\" in THING\n",
    "not \"\\n\" in THING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "247fdee7-6ba0-4249-9cfa-cad5d814bb24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s ='''argmax\n",
    "\"\"\"Review: {review}\\n\n",
    "Q: What is the underlying sentiment of this review and why?\\n\n",
    "A:[ANALYSIS]\\n\"\"\" \n",
    "from\n",
    "\"openai/text-davinci-003\"\n",
    "where \n",
    "len(TOKENS(ANALYSIS)) < 10\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9619f745-b147-4190-8318-656dbab15f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LMQLResult(prompt='Review: this\\nQ: What is the underlying sentiment of this review and why?\\nA: The underlying sentiment of this review is positive because\\n', variables={'ANALYSIS': ' The underlying sentiment of this review is positive because'}, distribution_variable=None, distribution_values=None)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await lmql.run(s.format(review='this'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d48eb092-3910-4471-b565-bd7251fb639f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s ='''argmax\n",
    "\"\"\"\n",
    "Give me different dad jokes in the following format:\n",
    "- one line joke. \n",
    "- one line joke. \n",
    "....\n",
    "for i in range(2):\n",
    "    -[THING]\n",
    "\"\"\"\n",
    "from\n",
    "\"openai/text-davinci-003\"\n",
    "where \n",
    "STOPS_AT(THING, \"\\n\")\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1aeb0191-efaa-44d2-8b42-8cdcffacd466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o = await lmql.run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c8aa08ac-4d16-4ed2-a244-48f0951a2109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Give me different dad jokes in the following format:\n",
      "- one line joke. \n",
      "- one line joke. \n",
      "....\n",
      "for i in range(2):\n",
      "    -Q: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(o[0].variables['THING'])\n",
    "print(o[0].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f4c9f0-d604-48ab-a29a-51f0a16902b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lexiflow] *",
   "language": "python",
   "name": "conda-env-lexiflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
